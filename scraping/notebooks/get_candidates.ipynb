{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.util import ngrams \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "import regex as re \n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np \n",
    "import json \n",
    "import random \n",
    "import spacy \n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('xx_sent_ud_sm')\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "label_map = {} \n",
    "with open('/scratch/useful/subject_set_labels.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        label_map.update(line)\n",
    "\n",
    "prop_dict = {} \n",
    "with open('/scratch/useful/ontology_props.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        prop_dict.update({line['name']: line['properties']})\n",
    "\n",
    "type_dict = {} \n",
    "with open('/scratch/useful/mapping_transitive.ttl', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        if(line[0] not in type_dict):\n",
    "            type_dict[line[0]] = set() \n",
    "        type_dict[line[0]].add(line[2].split('/')[-1])\n",
    "\n",
    "def get_prop_name(item):\n",
    "    if(\"#literal\" in item):\n",
    "        return item.split('#literal')[0], True\n",
    "    if(item in label_map):\n",
    "        tail_name = label_map[item]\n",
    "    else:\n",
    "        tail_name = re.sub('_', ' ',item.split('/')[-1])\n",
    "    return tail_name, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_types = [\"Place\", \"Person\", \"Organization\", \"Organisation\"]\n",
    "\n",
    "langs = ['ga', 'de', 'en']\n",
    "candidates = {} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ga\n",
      "0\n",
      "de\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "en\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n"
     ]
    }
   ],
   "source": [
    "for lang in langs:\n",
    "    print(lang)\n",
    "    with(open(f'/scratch/useful/abstracts_{lang}.jsonl', 'r')) as f:\n",
    "        # pb = tqdm.tqdm(total=1000000)\n",
    "        for i, line in enumerate(f):\n",
    "            # pb.update(1)\n",
    "            if(i%100000) == 0:\n",
    "                print(i)\n",
    "            item = json.loads(line)\n",
    "            rsc = item['resource']\n",
    "            txt = item['text']\n",
    "            found = False \n",
    "\n",
    "            for t in wanted_types:\n",
    "                if(f'{t}>' in type_dict[f'<{rsc}>']):\n",
    "                    found = True \n",
    "            \n",
    "            if(not(found)):\n",
    "                continue  \n",
    "\n",
    "            name = get_prop_name(rsc)[0]\n",
    "            if(name not in candidates):\n",
    "                candidates[name] = {}\n",
    "\n",
    "                properties = [] \n",
    "                fw_props = prop_dict[rsc]['properties']\n",
    "                for prop in fw_props:\n",
    "                    for item in fw_props[prop]:\n",
    "                        item_name = get_prop_name(item)[0]\n",
    "                        properties.append((name, prop, item_name))\n",
    "                \n",
    "                rv_props = prop_dict[rsc]['reverse_properties']\n",
    "                for prop in rv_props:\n",
    "                    for item in rv_props[prop][:3]:\n",
    "                        item_name = get_prop_name(item)[0]\n",
    "                        properties.append((item_name, prop, name))\n",
    "                \n",
    "                candidates[name]['properties'] = properties\n",
    "\n",
    "            doc = nlp(txt)\n",
    "            sents = [] \n",
    "            filtered_sents = []\n",
    "            for sent in doc.sents:                 \n",
    "                sents.append(sent.text)\n",
    "            \n",
    "            if(lang!='en'):\n",
    "                merged_sents = []\n",
    "                merge_next =  False\n",
    "                for sent in sents:\n",
    "                    if(re.search(r'\\d+\\.$', sent)):\n",
    "                        merge_next = True\n",
    "                        merged_sents.append(sent)\n",
    "                    else:\n",
    "                        if(merge_next):\n",
    "                            merged_sents[-1] = merged_sents[-1] + ' ' + sent\n",
    "                            merge_next = False\n",
    "                        else:\n",
    "                            merged_sents.append(sent)\n",
    "            else:\n",
    "                merged_sents = sents\n",
    "            \n",
    "            for sent in merged_sents:\n",
    "                if(len(sent.split()) > 5 and len(sent.split()) < 250):\n",
    "                    filtered_sents.append(sent)\n",
    "            candidates[name][f'{lang}_text'] = filtered_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'filtered_candidates.json'\n",
    "with open(save_name, 'w') as f:\n",
    "    json.dump(candidates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('textbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fc63c8ae42b05f54f8c8e4c73411ce0404f059987aac7c448c556c45688d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
