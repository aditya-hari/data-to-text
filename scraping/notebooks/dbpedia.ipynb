{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pickle \n",
    "import time \n",
    "import regex as re \n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from fuzzywuzzy import fuzz\n",
    "import spacy\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class TimedOut(Exception): pass\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds):\n",
    "    def signal_handler(signum, frame):\n",
    "        raise TimedOut(\"Timed out!\")\n",
    "    signal.signal(signal.SIGALRM, signal_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = pickle.load(open('all_content.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'<Label>([^<]*)</Label><URI>([^<]*)</URI>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('written',\n",
       " 'A Man Asleep',\n",
       " [['A Man Asleep (French: Un homme qui dort) is a 1967 novel by the French writer Georges Perec. It uses a second-person narrative, and follows a 25-year-old student, who one day decides to be indifferent about the world. A Man Asleep was adapted into a 1974 film, The Man Who Sleeps.'],\n",
       "  [\"The novel was published in France through Éditions Denoël in 1967. An English translation by Andrew Leak was published in 1990 through Collins Harvill in the United Kingdom and David R. Godine, Publisher in the United States, in a shared volume with Perec's first novel, Things: A Story of the Sixties.\"],\n",
       "  ['Upon the American release, Richard Eder of the Los Angeles Times compared the two novels of the volume—Things and A Man Asleep—and wrote that Things was \"the more engaging of the two, though less focused and ultimately, perhaps, less memorable.\" He wrote that in A Man Asleep, \"Perec shows a beauty on the far side of the void; a humanity on the far side of refusal.\"']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content['en']['A Man Asleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "de\n",
      "pt\n"
     ]
    }
   ],
   "source": [
    "for lang in all_content:\n",
    "    print(lang)\n",
    "    for title in all_content[lang]:\n",
    "        r = requests.get(f'https://lookup.dbpedia.org/api/search?query={title}')\n",
    "        if(r.status_code == 200):\n",
    "            match = re.findall(pattern, r.text)[0]\n",
    "            if(fuzz.ratio(match[0], title) > 80):\n",
    "                all_content[lang][title] = (match[1], all_content[lang][title][0], all_content[lang][title][1], all_content[lang][title][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content_dump = open('all_content_uris.pkl', 'wb')\n",
    "pickle.dump(all_content, all_content_dump)\n",
    "all_content_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f'https://lookup.dbpedia.org/api/search?query=A Man Asleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = pickle.load(open('all_content_uris.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content_uris = {'en': {}, 'pt': {}, 'de': {}}\n",
    "for lang in all_content:\n",
    "    for title in all_content[lang]:\n",
    "        if(len(all_content[lang][title]) == 4):\n",
    "            if(all_content[lang][title][0] == all_content[lang][title][1]):\n",
    "                continue \n",
    "            all_content_uris[lang][title] = {} \n",
    "            all_content_uris[lang][title]['uri'] = all_content[lang][title][0]\n",
    "            all_content_uris[lang][title]['category'] = all_content[lang][title][1]\n",
    "            all_content_uris[lang][title]['title'] = all_content[lang][title][2]\n",
    "            all_content_uris[lang][title]['content'] = all_content[lang][title][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dump = open('all_content_uris_sub.pkl', 'wb')\n",
    "pickle.dump(all_content_uris, final_dump)\n",
    "final_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_query = \"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "PREFIX dbp: <http://dbpedia.org/property/>\n",
    "\n",
    "SELECT ?property ?propertyLabel ?subject ?subjectLabel\n",
    "WHERE {\n",
    "  <ENTITY_URI> ?property ?subject .\n",
    "  \n",
    "  OPTIONAL {\n",
    "    ?property rdfs:label ?propertyLabel .\n",
    "    FILTER (langMatches(lang(?propertyLabel), \"en\"))\n",
    "  }\n",
    "  \n",
    "  OPTIONAL {\n",
    "    ?subject rdfs:label ?subjectLabel .\n",
    "    FILTER (langMatches(lang(?subjectLabel), \"en\"))\n",
    "  }\n",
    "  \n",
    "  FILTER (\n",
    "    ?property NOT IN (\n",
    "      <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>,\n",
    "      <http://purl.org/dc/terms/subject>, \n",
    "      <http://dbpedia.org/ontology/wikiPageWikiLink>, \n",
    "      <http://dbpedia.org/property/wikiPageUsesTemplate>,\n",
    "      <http://dbpedia.org/ontology/wikiPageRedirects>,\n",
    "      <http://dbpedia.org/property/align>,\n",
    "      <http://dbpedia.org/property/caption>,\n",
    "      <http://dbpedia.org/property/format>,\n",
    "      <http://dbpedia.org/property/float>,\n",
    "      <http://dbpedia.org/property/footer>,\n",
    "      <http://dbpedia.org/property/image>,\n",
    "      <http://dbpedia.org/property/width>,\n",
    "      <http://dbpedia.org/property/totalWidth>,\n",
    "      <http://dbpedia.org/property/imageCaption>,\n",
    "      <http://dbpedia.org/property/filename>,\n",
    "      <http://dbpedia.org/property/singleLine>,\n",
    "      <http://dbpedia.org/ontology/wikiPageDisambiguates>\n",
    "    )   &&\n",
    "    REGEX(STR(?property), \"^http://dbpedia.org/\")\n",
    "  )\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "subject_query = \"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "PREFIX dbp: <http://dbpedia.org/property/>\n",
    "\n",
    "SELECT ?property ?propertyLabel ?subject ?subjectLabel\n",
    "WHERE {\n",
    "  ?subject ?property <ENTITY_URI> .\n",
    "  \n",
    "  OPTIONAL {\n",
    "    ?property rdfs:label ?propertyLabel .\n",
    "    FILTER (langMatches(lang(?propertyLabel), \"en\"))\n",
    "  }\n",
    "  \n",
    "  OPTIONAL {\n",
    "    ?subject rdfs:label ?subjectLabel .\n",
    "    FILTER (langMatches(lang(?subjectLabel), \"en\"))\n",
    "  }\n",
    "  \n",
    "  FILTER (\n",
    "    ?property NOT IN (\n",
    "      <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>,\n",
    "      <http://purl.org/dc/terms/subject>, \n",
    "      <http://dbpedia.org/ontology/wikiPageWikiLink>, \n",
    "      <http://dbpedia.org/property/wikiPageUsesTemplate>,\n",
    "      <http://dbpedia.org/ontology/wikiPageRedirects>,\n",
    "      <http://dbpedia.org/property/align>,\n",
    "      <http://dbpedia.org/property/caption>,\n",
    "      <http://dbpedia.org/property/format>,\n",
    "      <http://dbpedia.org/property/float>,\n",
    "      <http://dbpedia.org/property/footer>,\n",
    "      <http://dbpedia.org/property/image>,\n",
    "      <http://dbpedia.org/property/width>,\n",
    "      <http://dbpedia.org/property/totalWidth>,\n",
    "      <http://dbpedia.org/property/imageCaption>,\n",
    "      <http://dbpedia.org/property/filename>,\n",
    "      <http://dbpedia.org/property/singleLine>,\n",
    "      <http://dbpedia.org/ontology/wikiPageDisambiguates>\n",
    "    )   &&\n",
    "    REGEX(STR(?property), \"^http://dbpedia.org/\")\n",
    "  )\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_uri = \"http://dbpedia.org/resource/Darkness_Visible_(memoir)\"\n",
    "query = re.sub(\"ENTITY_URI\", entity_uri, object_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/literaryGenre'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'literary genre'},\n",
       "  'subject': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Memoir'},\n",
       "  'subjectLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'Memoir'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/genre'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'genre'},\n",
       "  'subject': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Memoir'},\n",
       "  'subjectLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'Memoir'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/literaryGenre'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'literary genre'},\n",
       "  'subject': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Memoir'},\n",
       "  'subjectLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'Memoir'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/nonFictionSubject'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'non-fiction subject'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Major_depressive_disorder'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Major depressive disorder'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/subject'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'subject'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Major_depressive_disorder'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Major depressive disorder'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/nonFictionSubject'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'non-fiction subject'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Major_depressive_disorder'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Major depressive disorder'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/author'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'author'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/William_Styron'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'William Styron'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/author'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'author'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/William_Styron'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'William Styron'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/author'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'author'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/William_Styron'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'William Styron'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/mediaType'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'media type'},\n",
       "  'subject': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Hardcover'},\n",
       "  'subjectLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'Hardcover'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/mediaType'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'media type'},\n",
       "  'subject': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Hardcover'},\n",
       "  'subjectLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'Hardcover'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/property/publisher'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'publisher'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Random_House'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Random House'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/publisher'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'publisher'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Random_House'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Random House'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/publisher'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'publisher'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Random_House'},\n",
       "  'subjectLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Random House'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/name'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'name'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'A Memoir of Madness'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/name'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'name'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Darkness Visible:'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageID'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Wikipage page ID'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '6050875'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageID'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Wikipage page ID'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '6050875'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageRevisionID'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Wikipage revision ID'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '1110462903'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageRevisionID'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Wikipage revision ID'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '1110462903'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'https://www.npr.org/2014/12/17/371364727/25-years-ago-darkness-visible-broke-ground-detailing-depression'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'https://www.npr.org/2014/12/17/371364727/25-years-ago-darkness-visible-broke-ground-detailing-depression'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://www.vanityfair.com/magazine/archive/1989/12/styron198912'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://www.vanityfair.com/magazine/archive/1989/12/styron198912'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'https://www.theatlantic.com/entertainment/archive/2014/12/the-hope-that-william-styrons-darkness-visible-offers-25-years-later/383406/'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageExternalLink'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Link from a Wikipage to an external page'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'https://www.theatlantic.com/entertainment/archive/2014/12/the-hope-that-william-styrons-darkness-visible-offers-25-years-later/383406/'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/thumbnail'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'thumbnail'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/DarknessVisibleStyron.jpg?width=300'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/thumbnail'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'thumbnail'},\n",
       "  'subject': {'type': 'uri',\n",
       "   'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/DarknessVisibleStyron.jpg?width=300'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/congress'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'congress'},\n",
       "  'subject': {'type': 'literal', 'xml:lang': 'en', 'value': 'RC537.S88'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/country'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'country'},\n",
       "  'subject': {'type': 'literal', 'xml:lang': 'en', 'value': 'United States'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/dewey'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'dewey'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#double',\n",
       "   'value': '616.85'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/isbn'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'isbn'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '0'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/language'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'language'},\n",
       "  'subject': {'type': 'literal', 'xml:lang': 'en', 'value': 'English'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/property/mediaType'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'media type'},\n",
       "  'subject': {'type': 'literal', 'xml:lang': 'en', 'value': 'Print'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/pages'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'pages'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '84'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/property/pubDate'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'pub date'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#integer',\n",
       "   'value': '1990'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'de',\n",
       "   'value': 'Darkness Visible: A Memoir of Madness, auf Deutsch erschienen unter dem Titel Sturz in die Nacht: Die Geschichte einer Depression, ist ein autobiographisches Werk des amerikanischen Schriftstellers William Styron (1925–2006). Styron schildert darin eine Phase seines Lebens, in der er an einer suizidalen Depression litt. Es erschien erstmals im Dezember 1989 in der Zeitschrift Vanity Fair; für diesen Beitrag wurde Styron 1990 der National Magazine Award für den besten Essay des Jahres zugesprochen. 1990 erschien Darkness Visible in etwas erweiterter Form als Buch, verkaufte sich millionenfach und wurde in mehr als zwanzig Sprachen übersetzt. Der Text wurde nicht nur zu einem modernen Klassiker der amerikanischen Literatur, sondern wird auch häufiger in der psychiatrischen Literatur zitiert sowie in der psychotherapeutischen Ausbildung und Praxis eingesetzt.'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'de',\n",
       "   'value': 'Darkness Visible: A Memoir of Madness, auf Deutsch erschienen unter dem Titel Sturz in die Nacht: Die Geschichte einer Depression, ist ein autobiographisches Werk des amerikanischen Schriftstellers William Styron (1925–2006). Styron schildert darin eine Phase seines Lebens, in der er an einer suizidalen Depression litt. Es erschien erstmals im Dezember 1989 in der Zeitschrift Vanity Fair; für diesen Beitrag wurde Styron 1990 der National Magazine Award für den besten Essay des Jahres zugesprochen. 1990 erschien Darkness Visible in etwas erweiterter Form als Buch, verkaufte sich millionenfach und wurde in mehr als zwanzig Sprachen übersetzt. Der Text wurde nicht nur zu einem modernen Klassiker der amerikanischen Literatur, sondern wird auch häufiger in der psychiatrischen Literatur zitiert sowie in der psychotherapeutischen Ausbildung und Praxis eingesetzt.'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'fr',\n",
       "   'value': \"Face aux ténèbres : chronique d'une folie (Darkness Visible) est le récit autobiographique que fait l'auteur américain William Styron de sa dépression nerveuse. Sa première parution eut lieu dans le magazine Vanity Fair en 1989.\"}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'fr',\n",
       "   'value': \"Face aux ténèbres : chronique d'une folie (Darkness Visible) est le récit autobiographique que fait l'auteur américain William Styron de sa dépression nerveuse. Sa première parution eut lieu dans le magazine Vanity Fair en 1989.\"}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'ko',\n",
       "   'value': '( 윌리엄 골딩의 소설에 대해서는 문서를 참고하십시오.) 《보이는 어둠: 우울증에 대한 회고》(Darkness Visible: A Memoir of Madness)는 미국의 문학가 윌리엄 스타이런이 쓴 우울증에 대한 회고록이다. 윌리엄 스타이런은 이 책에서 자신이 우울증을 앓으면서 느꼈던 감정과 고통, 그리고 이를 극복하는 과정을 서술했다. 이 책의 내용은 1989년 12월에 잡지 배너티 페어의 기사로 처음 발행되었고, 이듬해인 1990년 이 기사는 수필 부문에 선정되었다. 이 기사의 내용을 바탕으로 같은 해 책이 출간되었고, 이 책은 많은 판매량을 기록하는 동시에 우울증에 대한 사회적 인식을 변화시키는 데에 기여했다. 현재 이 책은 현대 미국 문학의 대표적인 작품 중 하나로 거론될 뿐만 아니라, 정신의학 및 심리치료 분야에서 자주 인용되고 있다.'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'ko',\n",
       "   'value': '( 윌리엄 골딩의 소설에 대해서는 문서를 참고하십시오.) 《보이는 어둠: 우울증에 대한 회고》(Darkness Visible: A Memoir of Madness)는 미국의 문학가 윌리엄 스타이런이 쓴 우울증에 대한 회고록이다. 윌리엄 스타이런은 이 책에서 자신이 우울증을 앓으면서 느꼈던 감정과 고통, 그리고 이를 극복하는 과정을 서술했다. 이 책의 내용은 1989년 12월에 잡지 배너티 페어의 기사로 처음 발행되었고, 이듬해인 1990년 이 기사는 수필 부문에 선정되었다. 이 기사의 내용을 바탕으로 같은 해 책이 출간되었고, 이 책은 많은 판매량을 기록하는 동시에 우울증에 대한 사회적 인식을 변화시키는 데에 기여했다. 현재 이 책은 현대 미국 문학의 대표적인 작품 중 하나로 거론될 뿐만 아니라, 정신의학 및 심리치료 분야에서 자주 인용되고 있다.'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'es',\n",
       "   'value': 'Esa visible oscuridad: Memoria de la Locura es un relato del escritor de EE.UU. William Styron sobre su descenso en la depresión, y el triunfo de recuperación. Fue publicado primero en diciembre de 1989 en la revista Vanity Fair. La obra se originó en una conferencia que Styron originalmente dio en un simposio sobre desórdenes afectivos en el Departamento de Psiquiatría de la Escuela de Medicina en la Johns Hopkins University.\\u200b El título del trabajo proviene de la descripción de John Milton del infierno en Paraíso Perdido: Sin luz; más sólo la oscuridad visibleSirvió sólo para descubrir vistas de asombro,Regiones de pena, tristes sombras, donde la pazY el descanso nunca pueden vivir, la esperanza nunca vieneAquello viene a todo, pero tortura sin finAún inquieta, y un exaltado diluvio, alimentóCon azufre las eternas llamas sin consumir. Styron comienza su historia en octubre de 1985 cuando vuela a París para recibir el prestigioso Prix mondial Cino Del Duca. Durante este viaje, el estado mental del escritor empieza a deteriorarse rápidamente. Utilizando una mezcla de anécdotas, especulación, y reportaje, Styron reflexiona sobre las causas y efectos de la depresión, dibujando enlaces entre su propia enfermedad y la de otros escritores como Randall Jarrell, Albert Camus, Romain Gary, y Primo Levi, así como Presidente de EE.UU. Abraham Lincoln y la activista Abbie Hoffman. Styron conecta el inicio de su depresión con el corte repentino del uso que hizo del alcohol durante toda su vida, y argumenta que su condición probablemente pudo exacerbada por prescripción inadvertida del fármaco Halcion. Su depresión culmina en un episodio de ideación suicida intensa (aunque nunca haga un intento de suicidio real), el cual lo dirigió a una hospitalización y recuperación.\\u200b'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'es',\n",
       "   'value': 'Esa visible oscuridad: Memoria de la Locura es un relato del escritor de EE.UU. William Styron sobre su descenso en la depresión, y el triunfo de recuperación. Fue publicado primero en diciembre de 1989 en la revista Vanity Fair. La obra se originó en una conferencia que Styron originalmente dio en un simposio sobre desórdenes afectivos en el Departamento de Psiquiatría de la Escuela de Medicina en la Johns Hopkins University.\\u200b El título del trabajo proviene de la descripción de John Milton del infierno en Paraíso Perdido: Sin luz; más sólo la oscuridad visibleSirvió sólo para descubrir vistas de asombro,Regiones de pena, tristes sombras, donde la pazY el descanso nunca pueden vivir, la esperanza nunca vieneAquello viene a todo, pero tortura sin finAún inquieta, y un exaltado diluvio, alimentóCon azufre las eternas llamas sin consumir. Styron comienza su historia en octubre de 1985 cuando vuela a París para recibir el prestigioso Prix mondial Cino Del Duca. Durante este viaje, el estado mental del escritor empieza a deteriorarse rápidamente. Utilizando una mezcla de anécdotas, especulación, y reportaje, Styron reflexiona sobre las causas y efectos de la depresión, dibujando enlaces entre su propia enfermedad y la de otros escritores como Randall Jarrell, Albert Camus, Romain Gary, y Primo Levi, así como Presidente de EE.UU. Abraham Lincoln y la activista Abbie Hoffman. Styron conecta el inicio de su depresión con el corte repentino del uso que hizo del alcohol durante toda su vida, y argumenta que su condición probablemente pudo exacerbada por prescripción inadvertida del fármaco Halcion. Su depresión culmina en un episodio de ideación suicida intensa (aunque nunca haga un intento de suicidio real), el cual lo dirigió a una hospitalización y recuperación.\\u200b'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Darkness Visible: A Memoir of Madness is a memoir by American writer William Styron about his descent into depression and the triumph of recovery. It is among the last books published by Styron and is among his most celebrated. First published in December 1989 in Vanity Fair, the book grew out of a lecture that Styron originally delivered at a symposium on affective disorders at the Department of Psychiatry of the Johns Hopkins School of Medicine. Through the employment of anecdotes, speculation, and reportage, Styron reflects on the causes and effects of depression, drawing links between his own illness and that of other writers and public figures.'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/abstract'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'has abstract'},\n",
       "  'subject': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Darkness Visible: A Memoir of Madness is a memoir by American writer William Styron about his descent into depression and the triumph of recovery. It is among the last books published by Styron and is among his most celebrated. First published in December 1989 in Vanity Fair, the book grew out of a lecture that Styron originally delivered at a symposium on affective disorders at the Department of Psychiatry of the Johns Hopkins School of Medicine. Through the employment of anecdotes, speculation, and reportage, Styron reflects on the causes and effects of depression, drawing links between his own illness and that of other writers and public figures.'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageLength'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'page length (characters) of wiki page'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#nonNegativeInteger',\n",
       "   'value': '14467'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/wikiPageLength'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'page length (characters) of wiki page'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#nonNegativeInteger',\n",
       "   'value': '14467'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/dcc'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Dewey Decimal Classification'},\n",
       "  'subject': {'type': 'literal', 'value': \"616.85'27'0092\"}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/dcc'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'Dewey Decimal Classification'},\n",
       "  'subject': {'type': 'literal', 'value': \"616.85'27'0092\"}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/isbn'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'ISBN'},\n",
       "  'subject': {'type': 'literal', 'value': '0-394-58888-6'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/isbn'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'ISBN'},\n",
       "  'subject': {'type': 'literal', 'value': '0-394-58888-6'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/lcc'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'LCC'},\n",
       "  'subject': {'type': 'literal', 'value': 'RC537.S88'}},\n",
       " {'property': {'type': 'uri', 'value': 'http://dbpedia.org/ontology/lcc'},\n",
       "  'propertyLabel': {'type': 'literal', 'xml:lang': 'en', 'value': 'LCC'},\n",
       "  'subject': {'type': 'literal', 'value': 'RC537.S88'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/numberOfPages'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'number of pages'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#positiveInteger',\n",
       "   'value': '84'}},\n",
       " {'property': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/ontology/numberOfPages'},\n",
       "  'propertyLabel': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'number of pages'},\n",
       "  'subject': {'type': 'typed-literal',\n",
       "   'datatype': 'http://www.w3.org/2001/XMLSchema#positiveInteger',\n",
       "   'value': '84'}}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['results']['bindings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Darkness Visible (memoir)', 'Verbal Behavior', 'The Devil to Pay in the Backlands', 'Parmenides (dialogue)', 'Crito', \"Plato's unwritten doctrines\", 'Airbus A350', 'Airbus A320 family', 'Transall C-160', 'Boeing KC-135 Stratotanker', 'Bradley Fighting Vehicle', 'Rockwell B-1 Lancer', 'Messerschmitt Bf 108 Taifun', 'Boeing B-52 Stratofortress', 'Landing Vehicle Tracked', 'Boeing 737', 'Soyuz (spacecraft)', 'Flakpanzer Gepard', 'Dassault Rafale', 'Canberra', 'Uplengen', 'Beetzsee (municipality)', 'U2 (Berlin U-Bahn)', 'Kleinmachnow', 'Bhaktapur', 'Südbrookmerland', 'São Paulo', 'Moormerland', 'Memmingen', 'Wetzlar', 'Bombing of Dresden in World War II', 'Norden, Lower Saxony', 'Toronto', 'Schwieberdingen', 'Eberswalde', 'Freiburg im Breisgau', 'Fortifications of Frankfurt', 'Leipzig', 'Hattusa', 'Limes Germanicus', 'St. Nicholas Church, Potsdam', 'Poverty Point', 'Altes Stadthaus, Berlin', 'Federal Palace of Switzerland', 'The Whale House', 'Buried Pyramid', 'Sophienkirche', 'Salzhaus', \"Watkin's Tower\", 'Rötteln Castle', 'City Church of Bremgarten', 'Nietzsche Archive', \"St. Catherine's Church, Frankfurt\", 'St. Leonhard, Frankfurt', 'Saint Cyriakus, Gernrode', 'Reichstag building', 'Church of the Redeemer, Sacrow', 'Goetheanum', 'Minardi', 'France national football team', 'VfB Stuttgart', 'San Jose Sharks', 'New Zealand national rugby union team', 'Arminia Bielefeld', 'Switzerland national football team', 'FC Hansa Rostock', 'Australia national soccer team', 'FLN football team', 'Andrea Moda Formula', \"France women's national football team\", 'Kassel Huskies', 'Arsenal F.C.', 'Stade de Reims', 'Walter Benjamin', 'Apollo 1', 'Munir Bashir', 'Henry the Fowler', 'STS-117', 'Hilde Zimmermann', 'Fridtjof Nansen', 'Clara Schumann', 'Theodosius', 'Herman Moll', 'Angus Campbell (psychologist)', 'Siger of Brabant', 'Lewis Carroll', 'Richard Foerster (classical scholar)', 'Margaret of Valois', 'Sebastian Sailer', 'A Vindication of the Rights of Woman', 'A Vindication of the Rights of Men', 'Everything Tastes Better with Bacon', 'Boeing 747', 'Saab JAS 39 Gripen', 'September 11 attacks', 'McDonnell Douglas F-4 Phantom II in Australian service', 'Japanese aircraft carrier Akagi', 'Lockheed XF-104 Starfighter', 'Airbus A330', 'McDonnell XF-85 Goblin', 'USS Ranger (CV-4)', 'Republic F-84 Thunderjet', 'Paris', 'Goiânia', 'Parnamirim', 'São Mateus, Espírito Santo', 'Montes Claros', 'Campos Novos', 'Mossoró', 'Pará de Minas', 'Agnaldo Timóteo', 'Fundão, Espírito Santo', 'Hortolândia', 'São José dos Campos', 'Malta, Paraíba', 'Governador Valadares, Minas Gerais', 'Garanhuns', 'Pennsylvania Station (1910–1963)', 'History of Botafogo de Futebol e Regatas', 'Manchester United F.C. 9–0 Ipswich Town F.C.', 'SS Drottningholm', 'Alberto Henschel', 'Jean-Auguste-Dominique Ingres', 'Hans-Joachim Marseille', 'Thomas Baker (aviator)', 'Charles Messier', 'Frank Headlam', 'Grand Duchess Maria Nikolaevna of Russia', 'Albert, Prince Consort', 'Jimmy Kudo', 'Princess Louise, Duchess of Argyll', 'Victoria, Princess Royal', 'Attila', 'Fairfax Harrison', 'Apollo 11', 'Gregory of Nazianzus', 'Charles Darwin', 'Lawrence Wetherby', 'Edward VII', 'Theodoric Strabo'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_uris['en'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = re.sub(\"ENTITY_URI\", all_content_uris['en']['Everything Tastes Better with Bacon']['uri'], object_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "result_list_object = [] \n",
    "for result in results['results']['bindings']:\n",
    "    if('propertyLabel' in result and 'subjectLabel' in result):\n",
    "        result_list_object.append((result['propertyLabel']['value'], result['subjectLabel']['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_uris_subject = {'en': {}, 'pt': {}, 'de': {}}\n",
    "not_found_uris_object = {'en': {}, 'pt': {}, 'de': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "0 Darkness Visible (memoir)\n",
      "Timed out subject!\n",
      "1 Verbal Behavior\n",
      "2 The Devil to Pay in the Backlands\n",
      "Timed out object!\n",
      "Timed out subject!\n",
      "3 Parmenides (dialogue)\n",
      "4 Crito\n",
      "5 Plato's unwritten doctrines\n",
      "6 Airbus A350\n",
      "Timed out object!\n",
      "Timed out subject!\n",
      "7 Airbus A320 family\n",
      "Timed out object!\n",
      "8 Transall C-160\n",
      "9 Boeing KC-135 Stratotanker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out object!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     not_found_uris_object[lang][entity] \u001b[38;5;241m=\u001b[39m all_content_uris[lang][entity]\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m time_limit(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lang in all_content_uris:\n",
    "    print(lang)\n",
    "    for i, entity in enumerate(all_content_uris[lang]):\n",
    "        print(i, entity)\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            with time_limit(3):\n",
    "                query = re.sub(\"ENTITY_URI\", all_content_uris[lang][entity]['uri'], object_query)\n",
    "                sparql.setQuery(query)\n",
    "                sparql.setReturnFormat(JSON)\n",
    "                results = sparql.query().convert()\n",
    "                result_list_object = [] \n",
    "                for result in results['results']['bindings']:\n",
    "                    if('propertyLabel' in result and 'subjectLabel' in result):\n",
    "                        result_list_object.append((result['propertyLabel']['value'], result['subjectLabel']['value']))\n",
    "                all_content_uris[lang][entity]['object_properties'] = result_list_object\n",
    "        except TimedOut as e:   \n",
    "            print(\"Timed out object!\")\n",
    "            not_found_uris_object[lang][entity] = all_content_uris[lang][entity]\n",
    "\n",
    "        time.sleep(2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = open('all_content_uris_relations.pkl', 'wb')\n",
    "pickle.dump(all_content_uris, dump)\n",
    "dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_not_found_subject = open('not_found_uris_subject.pkl', 'wb')\n",
    "pickle.dump(not_found_uris_subject, dump_not_found_subject)\n",
    "dump_not_found_subject.close()\n",
    "\n",
    "dump_not_found_object = open('not_found_uris_object.pkl', 'wb')\n",
    "pickle.dump(not_found_uris_object, dump_not_found_object)\n",
    "dump_not_found_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content_uris_obj = pickle.load(open('all_content_uris_obj.pkl', 'rb'))\n",
    "all_content_uris_sub = pickle.load(open('all_content_uris_sub.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Darkness Visible (memoir)', 'Verbal Behavior', 'The Devil to Pay in the Backlands', 'Parmenides (dialogue)', 'Crito', \"Plato's unwritten doctrines\", 'Airbus A350', 'Airbus A320 family', 'Transall C-160', 'Boeing KC-135 Stratotanker', 'Bradley Fighting Vehicle', 'Rockwell B-1 Lancer', 'Messerschmitt Bf 108 Taifun', 'Boeing B-52 Stratofortress', 'Landing Vehicle Tracked', 'Boeing 737', 'Soyuz (spacecraft)', 'Flakpanzer Gepard', 'Dassault Rafale', 'Canberra', 'Uplengen', 'Beetzsee (municipality)', 'U2 (Berlin U-Bahn)', 'Kleinmachnow', 'Bhaktapur', 'Südbrookmerland', 'São Paulo', 'Moormerland', 'Memmingen', 'Wetzlar', 'Bombing of Dresden in World War II', 'Norden, Lower Saxony', 'Toronto', 'Schwieberdingen', 'Eberswalde', 'Freiburg im Breisgau', 'Fortifications of Frankfurt', 'Leipzig', 'Hattusa', 'Limes Germanicus', 'St. Nicholas Church, Potsdam', 'Poverty Point', 'Altes Stadthaus, Berlin', 'Federal Palace of Switzerland', 'The Whale House', 'Buried Pyramid', 'Sophienkirche', 'Salzhaus', \"Watkin's Tower\", 'Rötteln Castle', 'City Church of Bremgarten', 'Nietzsche Archive', \"St. Catherine's Church, Frankfurt\", 'St. Leonhard, Frankfurt', 'Saint Cyriakus, Gernrode', 'Reichstag building', 'Church of the Redeemer, Sacrow', 'Goetheanum', 'Minardi', 'France national football team', 'VfB Stuttgart', 'San Jose Sharks', 'New Zealand national rugby union team', 'Arminia Bielefeld', 'Switzerland national football team', 'FC Hansa Rostock', 'Australia national soccer team', 'FLN football team', 'Andrea Moda Formula', \"France women's national football team\", 'Kassel Huskies', 'Arsenal F.C.', 'Stade de Reims', 'Walter Benjamin', 'Apollo 1', 'Munir Bashir', 'Henry the Fowler', 'STS-117', 'Hilde Zimmermann', 'Fridtjof Nansen', 'Clara Schumann', 'Theodosius', 'Herman Moll', 'Angus Campbell (psychologist)', 'Siger of Brabant', 'Lewis Carroll', 'Richard Foerster (classical scholar)', 'Margaret of Valois', 'Sebastian Sailer', 'A Vindication of the Rights of Woman', 'A Vindication of the Rights of Men', 'Everything Tastes Better with Bacon', 'Boeing 747', 'Saab JAS 39 Gripen', 'September 11 attacks', 'McDonnell Douglas F-4 Phantom II in Australian service', 'Japanese aircraft carrier Akagi', 'Lockheed XF-104 Starfighter', 'Airbus A330', 'McDonnell XF-85 Goblin', 'USS Ranger (CV-4)', 'Republic F-84 Thunderjet', 'Paris', 'Goiânia', 'Parnamirim', 'São Mateus, Espírito Santo', 'Montes Claros', 'Campos Novos', 'Mossoró', 'Pará de Minas', 'Agnaldo Timóteo', 'Fundão, Espírito Santo', 'Hortolândia', 'São José dos Campos', 'Malta, Paraíba', 'Governador Valadares, Minas Gerais', 'Garanhuns', 'Pennsylvania Station (1910–1963)', 'History of Botafogo de Futebol e Regatas', 'Manchester United F.C. 9–0 Ipswich Town F.C.', 'SS Drottningholm', 'Alberto Henschel', 'Jean-Auguste-Dominique Ingres', 'Hans-Joachim Marseille', 'Thomas Baker (aviator)', 'Charles Messier', 'Frank Headlam', 'Grand Duchess Maria Nikolaevna of Russia', 'Albert, Prince Consort', 'Jimmy Kudo', 'Princess Louise, Duchess of Argyll', 'Victoria, Princess Royal', 'Attila', 'Fairfax Harrison', 'Apollo 11', 'Gregory of Nazianzus', 'Charles Darwin', 'Lawrence Wetherby', 'Edward VII', 'Theodoric Strabo'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_uris_obj['en'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_content_uris_obj['en']['Apollo 11']['object_properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_content_uris_sub['en']['Apollo 11']['object_properties']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in all_content_uris_obj:\n",
    "    for title in all_content_uris_obj[lang]:\n",
    "        if('object_properties' in all_content_uris_obj[lang][title]):\n",
    "            all_content_uris_obj[lang][title]['object_properties'] = list(set(all_content_uris_obj[lang][title]['object_properties']))\n",
    "        else:\n",
    "            all_content_uris_obj[lang][title]['object_properties'] = []\n",
    "            \n",
    "        if('object_properties' in all_content_uris_sub[lang][title]):\n",
    "            all_content_uris_obj[lang][title]['subject_properties'] = list(set(all_content_uris_sub[lang][title]['object_properties']))\n",
    "        else:\n",
    "            all_content_uris_obj[lang][title]['subject_properties'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uri', 'category', 'title', 'content', 'object_properties', 'subject_properties'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_uris_obj['en']['Apollo 11'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "pt\n",
      "de\n"
     ]
    }
   ],
   "source": [
    "for lang in all_content_uris_obj:\n",
    "    print(lang)\n",
    "    if(lang == 'en'):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "    elif(lang == 'pt'):\n",
    "        nlp = spacy.load('pt_core_news_sm')\n",
    "    elif(lang == 'de'):\n",
    "        nlp = spacy.load('de_core_news_sm')\n",
    "    for title in all_content_uris_obj[lang]:\n",
    "        content = all_content_uris_obj[lang][title]['content']\n",
    "        sent_content = []\n",
    "        for para in content:\n",
    "            doc = nlp(\" \".join(para))\n",
    "            sentences = list(doc.sents)\n",
    "            sent_content.append(sentences)\n",
    "        all_content_uris_obj[lang][title]['sentences'] = sent_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Alberto Henschel (Berlim, 13 de Junho de 1827 — Rio de Janeiro(A), 30 de Junho de 1882) foi um fotógrafo teuto-brasileiro, considerado o mais diligente empresário da fotografia no Brasil do século XIX, com escritórios em Pernambuco, Bahia, Rio de Janeiro e São Paulo, Henschel foi também responsável pela vinda de outros fotógrafos profissionais ao país, como o seu compatriota Karl Ernest Papf — com quem trabalharia mais tarde — e seu filho, Jorge Henrique Papf, que sucederia ao pai no ramo da fotografia.,\n",
       "  Henschel ficou conhecido por produzir belas imagens do Rio de Janeiro como fotógrafo paisagista e por ser um excelente retratista, o que lhe rendeu o título de Photographo da Casa Imperial, habilitando-o a retratar o cotidiano da monarquia brasileira durante o Segundo Reinado, inclusive fotografando o imperador Dom Pedro II e sua família.,\n",
       "  Esse título valorizaria muito suas fotos, inclusive no preço.,\n",
       "  Mas, certamente, sua principal contribuição à história da fotografia no Brasil foi o registro fotográfico de todos os extratos sociais do Brasil oitocentista: retratos, geralmente no padrão carte-de-visite, foram tirados da nobreza, dos ricos comerciantes, da classe média e dos negros, tanto livres como escravos, em um período ainda anterior à lei Áurea.],\n",
       " [Logo quando os primeiros mapas-múndi que mostravam o Brasil foram impressos, na época renascentista de Albrecht Dürer, o país-continente recém-descoberto despertou o interesse da Alemanha.,\n",
       "  Um dos principais fatores de atração que o Brasil exercia para com os alemães é decorrente das empolgantes narrativas e ilustrações a respeito dos índios, das paisagens exóticas, das riquezas de animais selvagens e novas espécies de plantas, relatadas primeiramente nas obras fantásticas de Hans Staden, seguido por aventureiros e cientistas como Johann Baptist Emanuel Pohl, autor de Viagem no Interior do Brasil.,\n",
       "  Empreendida nos Anos de 1817 a 1821 e Publicada por Ordem de Sua Majestade o Imperador da Áustria Francisco Primeiro, em que descreve sua viagem pelo país, com observações entusiásticas e elogiosas, acompanhadas de luxuriantes ilustrações.,\n",
       "  Sobre o Rio de Janeiro, Pohl escreveria:,\n",
       "  Certamente essas narrativas e ilustrações constituíram um dos principais fatores de atração para os fotógrafos alemães oitocentistas que se transfeririam para o Brasil, como Revert Henrique Klumb, Augusto Stahl, Karl Ernest Papf e Alberto Henschel.],\n",
       " [Não há registro da vida pessoal e profissional de Alberto Henschel na Alemanha, nem das razões que o teriam levado a emigrar para o Brasil.,\n",
       "  Sabe-se apenas que era filho de Moritz e Helene Henschel.,\n",
       "  Moritz e seus irmãos August, Friedrich e Wilhelm, de origem judaica, chegaram em Berlim por volta de 1806, tendo se notabilizado como gravuristas e assinado suas obras como Irmãos Henschel.,\n",
       "  Supõe-se que Alberto Henschel conheceu o também fotógrafo Francisco Benque ainda na Alemanha, com quem teria uma bem-sucedida, porém efêmera, sociedade no Brasil.,\n",
       "  Henschel desembarcou no Recife em maio de 1866, junto com o também alemão Karl Heinrich Gutzlaff, com quem associou-se para criar um estúdio fotográfico na rua do Imperador, número 38.,\n",
       "  Inicialmente denominado Alberto Henschel & Cia, o estúdio passou a chamar-se Photographia Allemã, mudando-se em seguida para novo endereço, no largo da Matriz de Santo Antônio, número 2.,\n",
       "  Pelo fato de ter montado seu negócio logo que chegou ao Brasil, presume-se que Alberto já fosse um experiente fotógrafo e tencionasse engajar-se no promissor negócio da fotografia em um mercado ainda pouco explorado.,\n",
       "  Em 1867, Henschel dissociou-se de Gutzlaff e voltou à Alemanha, onde atualizou sua técnica e adquiriu novos equipamentos para o seu ateliê de fotografia.,\n",
       "  Retornou ao Brasil no mesmo ano, abrindo outro estabelecimento com a mesma razão social na cidade de Salvador, na rua da Piedade, número 16.Abrindo três estabelecimentos em apenas dois anos, Henschel já era considerado o mais ousado e atilado empresário da fotografia no Brasil oitocentista.,\n",
       "  No fim dos anos 1860, as casas de Recife e Salvador já produziam retratos de pessoas de origem africana, escravas e livres, com a diferença de retratá-las à vontade e com dignidade, como indivíduos e não como objetos.,\n",
       "  Em 1870, Henschel abriu outra filial de seu ateliê, desta vez no Rio de Janeiro, na rua dos Ourives (atual rua Miguel Couto, número 40).,\n",
       "  Foi no Rio, capital do Império, que começaria sua próspera parceria com Francisco Benque.,\n",
       "  Com o nome de Henschel & Benque, os dois especializaram-se na produção e comercialização de retratos e paisagens, além das fotopinturas feitas por Karl Ernest Papf.,\n",
       "  Não há registro datando quando a sociedade com Benque desfez-se, mas é provável que a sociedade tenha perdurado até 1880.Pela qualidade de seu trabalho e pelo sucesso que fizera na Corte, Henschel foi agraciado com o título de Photographo da Casa Imperial, em 7 de Setembro de 1874, juntamente com Benque.,\n",
       "  O historiador fotográfico Gilberto Ferrez descreve a qualidade e importância de Henschel da seguinte maneira:,\n",
       "  Henschel participou de várias exposições fotográficas, destacando-se na exposição da Academia Imperial de Belas Artes em 1872 e 1875, pela qual recebeu a Medalha de Ouro na primeira edição.,\n",
       "  Também participou da IV Exposição Nacional e da Exposição Universal de Viena, na Áustria, na qual obteve a Medalha de Mérito.,\n",
       "  Em 1 de Fevereiro de 1882(B), Alberto inaugurou mais um estabelecimento, desta vez na capital da província de São Paulo, com a denominação de Photographia Imperial, porque o nome Photographia Allemã já era utilizado pelo ateliê do fotógrafo Carlos Hoenen desde 1875.,\n",
       "  Sua chegada a São Paulo foi vista com muita importância, pois, além de ser detentor do prestigioso título de Photographo da Casa Imperial, ele vinha direto da Corte.,\n",
       "  O jornal A Província de São Paulo, ao descrever nos mínimos detalhes o novo ateliê em sua edição do dia da inauguração, demonstrou o entusiasmo com que Henschel foi recebido pelos paulistas.,\n",
       "  Henschel morreria no mesmo ano, apenas alguns meses após estabelecer-se em São Paulo.,\n",
       "  Entretanto, suas empresas, sob o comando de outros empresários, continuariam estrategicamente utilizando seu nome ainda por vários anos, tendo em vista o grande prestígio que a marca \"Henschel\" adquirira.],\n",
       " [Não há registro da vida pessoal e profissional de Alberto Henschel na Alemanha, nem das razões que o teriam levado a emigrar para o Brasil.,\n",
       "  Sabe-se apenas que era filho de Moritz e Helene Henschel.,\n",
       "  Moritz e seus irmãos August, Friedrich e Wilhelm, de origem judaica, chegaram em Berlim por volta de 1806, tendo se notabilizado como gravuristas e assinado suas obras como Irmãos Henschel.,\n",
       "  Supõe-se que Alberto Henschel conheceu o também fotógrafo Francisco Benque ainda na Alemanha, com quem teria uma bem-sucedida, porém efêmera, sociedade no Brasil.],\n",
       " [Henschel desembarcou no Recife em maio de 1866, junto com o também alemão Karl Heinrich Gutzlaff, com quem associou-se para criar um estúdio fotográfico na rua do Imperador, número 38.,\n",
       "  Inicialmente denominado Alberto Henschel & Cia, o estúdio passou a chamar-se Photographia Allemã, mudando-se em seguida para novo endereço, no largo da Matriz de Santo Antônio, número 2.,\n",
       "  Pelo fato de ter montado seu negócio logo que chegou ao Brasil, presume-se que Alberto já fosse um experiente fotógrafo e tencionasse engajar-se no promissor negócio da fotografia em um mercado ainda pouco explorado.,\n",
       "  Em 1867, Henschel dissociou-se de Gutzlaff e voltou à Alemanha, onde atualizou sua técnica e adquiriu novos equipamentos para o seu ateliê de fotografia.,\n",
       "  Retornou ao Brasil no mesmo ano, abrindo outro estabelecimento com a mesma razão social na cidade de Salvador, na rua da Piedade, número 16.Abrindo três estabelecimentos em apenas dois anos, Henschel já era considerado o mais ousado e atilado empresário da fotografia no Brasil oitocentista.,\n",
       "  No fim dos anos 1860, as casas de Recife e Salvador já produziam retratos de pessoas de origem africana, escravas e livres, com a diferença de retratá-las à vontade e com dignidade, como indivíduos e não como objetos.,\n",
       "  Em 1870, Henschel abriu outra filial de seu ateliê, desta vez no Rio de Janeiro, na rua dos Ourives (atual rua Miguel Couto, número 40).,\n",
       "  Foi no Rio, capital do Império, que começaria sua próspera parceria com Francisco Benque.,\n",
       "  Com o nome de Henschel & Benque, os dois especializaram-se na produção e comercialização de retratos e paisagens, além das fotopinturas feitas por Karl Ernest Papf.,\n",
       "  Não há registro datando quando a sociedade com Benque desfez-se, mas é provável que a sociedade tenha perdurado até 1880.Pela qualidade de seu trabalho e pelo sucesso que fizera na Corte, Henschel foi agraciado com o título de Photographo da Casa Imperial, em 7 de Setembro de 1874, juntamente com Benque.,\n",
       "  O historiador fotográfico Gilberto Ferrez descreve a qualidade e importância de Henschel da seguinte maneira:,\n",
       "  Henschel participou de várias exposições fotográficas, destacando-se na exposição da Academia Imperial de Belas Artes em 1872 e 1875, pela qual recebeu a Medalha de Ouro na primeira edição.,\n",
       "  Também participou da IV Exposição Nacional e da Exposição Universal de Viena, na Áustria, na qual obteve a Medalha de Mérito.,\n",
       "  Em 1 de Fevereiro de 1882(B), Alberto inaugurou mais um estabelecimento, desta vez na capital da província de São Paulo, com a denominação de Photographia Imperial, porque o nome Photographia Allemã já era utilizado pelo ateliê do fotógrafo Carlos Hoenen desde 1875.,\n",
       "  Sua chegada a São Paulo foi vista com muita importância, pois, além de ser detentor do prestigioso título de Photographo da Casa Imperial, ele vinha direto da Corte.,\n",
       "  O jornal A Província de São Paulo, ao descrever nos mínimos detalhes o novo ateliê em sua edição do dia da inauguração, demonstrou o entusiasmo com que Henschel foi recebido pelos paulistas.,\n",
       "  Henschel morreria no mesmo ano, apenas alguns meses após estabelecer-se em São Paulo.,\n",
       "  Entretanto, suas empresas, sob o comando de outros empresários, continuariam estrategicamente utilizando seu nome ainda por vários anos, tendo em vista o grande prestígio que a marca \"Henschel\" adquirira.],\n",
       " [Henschel desembarcou no Recife em maio de 1866, junto com o também alemão Karl Heinrich Gutzlaff, com quem associou-se para criar um estúdio fotográfico na rua do Imperador, número 38.,\n",
       "  Inicialmente denominado Alberto Henschel & Cia, o estúdio passou a chamar-se Photographia Allemã, mudando-se em seguida para novo endereço, no largo da Matriz de Santo Antônio, número 2.,\n",
       "  Pelo fato de ter montado seu negócio logo que chegou ao Brasil, presume-se que Alberto já fosse um experiente fotógrafo e tencionasse engajar-se no promissor negócio da fotografia em um mercado ainda pouco explorado.,\n",
       "  Em 1867, Henschel dissociou-se de Gutzlaff e voltou à Alemanha, onde atualizou sua técnica e adquiriu novos equipamentos para o seu ateliê de fotografia.,\n",
       "  Retornou ao Brasil no mesmo ano, abrindo outro estabelecimento com a mesma razão social na cidade de Salvador, na rua da Piedade, número 16.Abrindo três estabelecimentos em apenas dois anos, Henschel já era considerado o mais ousado e atilado empresário da fotografia no Brasil oitocentista.,\n",
       "  No fim dos anos 1860, as casas de Recife e Salvador já produziam retratos de pessoas de origem africana, escravas e livres, com a diferença de retratá-las à vontade e com dignidade, como indivíduos e não como objetos.],\n",
       " [Em 1870, Henschel abriu outra filial de seu ateliê, desta vez no Rio de Janeiro, na rua dos Ourives (atual rua Miguel Couto, número 40).,\n",
       "  Foi no Rio, capital do Império, que começaria sua próspera parceria com Francisco Benque.,\n",
       "  Com o nome de Henschel & Benque, os dois especializaram-se na produção e comercialização de retratos e paisagens, além das fotopinturas feitas por Karl Ernest Papf.,\n",
       "  Não há registro datando quando a sociedade com Benque desfez-se, mas é provável que a sociedade tenha perdurado até 1880.Pela qualidade de seu trabalho e pelo sucesso que fizera na Corte, Henschel foi agraciado com o título de Photographo da Casa Imperial, em 7 de Setembro de 1874, juntamente com Benque.,\n",
       "  O historiador fotográfico Gilberto Ferrez descreve a qualidade e importância de Henschel da seguinte maneira:,\n",
       "  Henschel participou de várias exposições fotográficas, destacando-se na exposição da Academia Imperial de Belas Artes em 1872 e 1875, pela qual recebeu a Medalha de Ouro na primeira edição.,\n",
       "  Também participou da IV Exposição Nacional e da Exposição Universal de Viena, na Áustria, na qual obteve a Medalha de Mérito.],\n",
       " [Em 1 de Fevereiro de 1882(B), Alberto inaugurou mais um estabelecimento, desta vez na capital da província de São Paulo, com a denominação de Photographia Imperial, porque o nome Photographia Allemã já era utilizado pelo ateliê do fotógrafo Carlos Hoenen desde 1875.,\n",
       "  Sua chegada a São Paulo foi vista com muita importância, pois, além de ser detentor do prestigioso título de Photographo da Casa Imperial, ele vinha direto da Corte.,\n",
       "  O jornal A Província de São Paulo, ao descrever nos mínimos detalhes o novo ateliê em sua edição do dia da inauguração, demonstrou o entusiasmo com que Henschel foi recebido pelos paulistas.,\n",
       "  Henschel morreria no mesmo ano, apenas alguns meses após estabelecer-se em São Paulo.,\n",
       "  Entretanto, suas empresas, sob o comando de outros empresários, continuariam estrategicamente utilizando seu nome ainda por vários anos, tendo em vista o grande prestígio que a marca \"Henschel\" adquirira.],\n",
       " [Henschel sempre se manteve atualizado com as últimas novidades técnicas do mercado fotográfico.,\n",
       "  Quando o padrão estético de fotografia carte-de-visite começou a ganhar o mundo, Henschel já dominava a técnica, a qual utilizou em grande escala em seus estabelecimentos.,\n",
       "  Seus estúdios possuíam equipamentos de última geração, adequados para o retrato instantâneo de crianças que, irrequietas, eram a dor de cabeça dos fotógrafos.,\n",
       "  Em um anúncio presente no Novo Almanach de São Paulo para o Anno de 1883, Henschel propagandeava:,\n",
       "  O novo processo a que o anúncio se referia era o uso de placas secas de gelatina transparente, utilizadas como camada adesiva para a fixação dos sais de prata sobre o papel.],\n",
       " [Nota (A):,\n",
       "  Algumas biografias do fotógrafo apontam o local de seu falecimento como sendo em São Paulo.]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_uris_obj['pt']['Alberto Henschel']['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "pt\n",
      "de\n"
     ]
    }
   ],
   "source": [
    "for lang in all_content_uris_obj:\n",
    "    print(lang)\n",
    "    if(lang == 'en'):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "    elif(lang == 'pt'):\n",
    "        nlp = spacy.load('pt_core_news_sm')\n",
    "    elif(lang == 'de'):\n",
    "        nlp = spacy.load('de_core_news_sm')\n",
    "    for title in all_content_uris_obj[lang]:\n",
    "        paras = []\n",
    "        for para in all_content_uris_obj[lang][title]['sentences']:\n",
    "            filtered_sents = [] \n",
    "            for sent in para:\n",
    "                document = nlp(sent.text)\n",
    "                tok_tags = [token.pos_ for token in document]\n",
    "                if('NOUN' in tok_tags or 'PROPN' in tok_tags or 'PRON' in tok_tags or 'ADJ' in tok_tags or 'VERB' in tok_tags or 'ADV' in tok_tags):\n",
    "                    filtered_sents.append(sent.text)\n",
    "            paras.append(filtered_sents)\n",
    "        all_content_uris_obj[lang][title]['filtered_sentences'] = paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "pt\n",
      "de\n"
     ]
    }
   ],
   "source": [
    "for lang in all_content_uris_obj:\n",
    "    print(lang)\n",
    "    for title in all_content_uris_obj[lang]:\n",
    "        paras = []\n",
    "        for para in all_content_uris_obj[lang][title]['filtered_sentences']:\n",
    "            filtered_sents = [sent for sent in para if len(sent.split(\" \"))>5 and len(sent.split(\" \"))<100] \n",
    "            paras.append(filtered_sents)\n",
    "        all_content_uris_obj[lang][title]['actual_filtered_sentences'] = paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_content = {'en': {}, 'pt': {}, 'de': {}}\n",
    "for lang in all_content_uris_obj:\n",
    "    for title in all_content_uris_obj[lang]:\n",
    "        if(len(all_content_uris_obj[lang][title]['filtered_sentences']) > 0) and (len(all_content_uris_obj[lang][title]['object_properties']) + len(all_content_uris_obj[lang][title]['subject_properties']) > 0):\n",
    "            final_content[lang][title] = {}\n",
    "            final_content[lang][title]['uri'] = all_content_uris_obj[lang][title]['uri']\n",
    "            final_content[lang][title]['content'] = all_content_uris_obj[lang][title]['content']\n",
    "            final_content[lang][title]['filtered_sentences'] = all_content_uris_obj[lang][title]['filtered_sentences']\n",
    "            final_content[lang][title]['len_filtered_sentences'] = all_content_uris_obj[lang][title]['actual_filtered_sentences']\n",
    "            final_content[lang][title]['object_properties'] = all_content_uris_obj[lang][title]['object_properties']\n",
    "            final_content[lang][title]['subject_properties'] = all_content_uris_obj[lang][title]['subject_properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dump = open('sents_facts.pkl', 'wb')\n",
    "pickle.dump(final_content, final_dump)\n",
    "final_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_content = pickle.load(open('sents_facts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"deu_Latn\")\n",
    "pt_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"por_Latn\")\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(256206, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\").to('cuda')\n",
    "nllb_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_candidates = {'de': {'sents':[], 'src':[]}, 'pt': {'sents':[], 'src':[]}}\n",
    "for lang in final_content:\n",
    "    if(lang != 'en'):\n",
    "        for title in final_content[lang]:\n",
    "            src_para = [] \n",
    "            for i, sent in enumerate(final_content[lang][title]['len_filtered_sentences']):\n",
    "                trans_candidates[lang]['sents'].extend(sent)\n",
    "                trans_candidates[lang]['src'].extend((title, i) for _ in range(len(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_candidates['pt']['sents'])//128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_sents = {'de': [], 'pt': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in trans_candidates:\n",
    "    outs = [] \n",
    "    if(lang == 'de'):\n",
    "        tokenizer = de_tokenizer\n",
    "    elif(lang == 'pt'):\n",
    "        tokenizer = pt_tokenizer\n",
    "    sents_batched = [trans_candidates[lang]['sents'][i:i+32] for i in range(0, len(trans_candidates[lang]['sents']), 32)]\n",
    "    for i, batch in enumerate(sents_batched):\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "        translated_tokens = nllb_model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id['eng_Latn'], max_length=400)\n",
    "        out = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)    \n",
    "        outs.extend(out)\n",
    "    translated_sents[lang] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dump = open('translated_sents.pkl', 'wb')\n",
    "pickle.dump(translated_sents, trans_dump)\n",
    "trans_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mapping = {'de': {}, 'pt': {}}\n",
    "for lang in trans_candidates:\n",
    "    for sent, mapping in zip(translated_sents[lang], trans_candidates[lang]['src']):\n",
    "        if(mapping[0] not in trans_mapping[lang]):\n",
    "            trans_mapping[lang][mapping[0]] = [[]]\n",
    "        if(mapping[1] >= len(trans_mapping[lang][mapping[0]])):\n",
    "            trans_mapping[lang][mapping[0]].append([])\n",
    "        trans_mapping[lang][mapping[0]][mapping[1]].append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_mapping['de']['Landing Vehicle Tracked'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in final_content:\n",
    "    if(lang == 'en'):\n",
    "        for title in final_content[lang]:\n",
    "            final_content[lang][title]['translated_sents'] = [] \n",
    "    else:\n",
    "        for title in final_content[lang]:\n",
    "            final_content[lang][title]['translated_sents'] = trans_mapping[lang][title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_content = pickle.load(open('final_dump.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_facts_candidates = {'pt': {'facts': [], 'src': []}, 'de': {'facts': [], 'src': []}}\n",
    "for lang in final_content:\n",
    "    if(lang == 'en'):\n",
    "        continue \n",
    "    for title in final_content[lang]:\n",
    "        obj_facts_candidates[lang]['facts'].extend([(title, fc[0], fc[1]) for fc in final_content[lang][title]['object_properties']])\n",
    "        obj_facts_candidates[lang]['src'].extend([title for _ in range(len(final_content[lang][title]['object_properties']))])\n",
    "\n",
    "sub_facts_candidates = {'pt': {'facts': [], 'src': []}, 'de': {'facts': [], 'src': []}}\n",
    "for lang in final_content:\n",
    "    if(lang == 'en'):\n",
    "        continue\n",
    "    for title in final_content[lang]:\n",
    "        sub_facts_candidates[lang]['facts'].extend([(fc[1], fc[0], title) for fc in final_content[lang][title]['subject_properties']])\n",
    "        sub_facts_candidates[lang]['src'].extend([title for _ in range(len(final_content[lang][title]['subject_properties']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_facts = {'sub':{'de': [], 'pt': []}, 'obj': {'de': [], 'pt': []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in obj_facts_candidates:\n",
    "    outs = [] \n",
    "    if(lang == 'de'):\n",
    "        out_lang = 'deu_Latn'\n",
    "    elif(lang == 'pt'):\n",
    "        out_lang = 'por_Latn'\n",
    "    fact_sents = [f for fact in obj_facts_candidates[lang]['facts'] for f in fact]\n",
    "    sents_batched = [fact_sents[i:i+32] for i in range(0, len(fact_sents), 32)]\n",
    "    for i, batch in enumerate(sents_batched):\n",
    "        inputs = en_tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "        translated_tokens = nllb_model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[out_lang], max_length=400)\n",
    "        out = en_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)    \n",
    "        outs.extend(out)\n",
    "    translated_facts['obj'][lang] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in sub_facts_candidates:\n",
    "    outs = [] \n",
    "    if(lang == 'de'):\n",
    "        out_lang = 'deu_Latn'\n",
    "    elif(lang == 'pt'):\n",
    "        out_lang = 'por_Latn'\n",
    "    fact_sents = [f for fact in sub_facts_candidates[lang]['facts'] for f in fact]\n",
    "    sents_batched = [fact_sents[i:i+32] for i in range(0, len(fact_sents), 32)]\n",
    "    for i, batch in enumerate(sents_batched):\n",
    "        inputs = en_tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "        translated_tokens = nllb_model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[out_lang], max_length=400)\n",
    "        out = en_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)    \n",
    "        outs.extend(out)\n",
    "    translated_facts['sub'][lang] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in translated_facts:\n",
    "    for lang in translated_facts[split]:\n",
    "        translated_facts[split][lang] = [translated_facts[split][lang][i:i+3] for i in range(0, len(translated_facts[split][lang]), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_facts_dump = open('translated_facts.pkl', 'wb')\n",
    "pickle.dump(translated_facts, translated_facts_dump)\n",
    "translated_facts_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_obj_mapping = {'de': {}, 'pt': {}}\n",
    "for lang in obj_facts_candidates:\n",
    "    for sent, mapping in zip(translated_facts['obj'][lang], obj_facts_candidates[lang]['src']):\n",
    "        if(mapping not in trans_obj_mapping[lang]):\n",
    "            trans_obj_mapping[lang][mapping] = []\n",
    "        trans_obj_mapping[lang][mapping].append(sent)\n",
    "\n",
    "trans_sub_mapping = {'de': {}, 'pt': {}}\n",
    "for lang in sub_facts_candidates:\n",
    "    for sent, mapping in zip(translated_facts['sub'][lang], sub_facts_candidates[lang]['src']):\n",
    "        if(mapping not in trans_sub_mapping[lang]):\n",
    "            trans_sub_mapping[lang][mapping] = []\n",
    "        trans_sub_mapping[lang][mapping].append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(final_content['de'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(trans_obj_mapping['de'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in final_content:\n",
    "    if(lang == 'en'):\n",
    "        for title in final_content[lang]:\n",
    "            final_content[lang][title]['translated_object_properties'] = [] \n",
    "    else:\n",
    "        for title in final_content[lang]:\n",
    "            if(title not in trans_obj_mapping[lang]):\n",
    "                final_content[lang][title]['translated_object_properties'] = []\n",
    "            else:\n",
    "                final_content[lang][title]['translated_object_properties'] = trans_obj_mapping[lang][title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in final_content:\n",
    "    if(lang == 'en'):\n",
    "        for title in final_content[lang]:\n",
    "            final_content[lang][title]['translated_subject_properties'] = [] \n",
    "    else:\n",
    "        for title in final_content[lang]:\n",
    "            if(title not in trans_sub_mapping[lang]):\n",
    "                final_content[lang][title]['translated_subject_properties'] = []\n",
    "            else:\n",
    "                final_content[lang][title]['translated_subject_properties'] = trans_sub_mapping[lang][title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dump = open('all_data.pkl', 'wb')\n",
    "pickle.dump(final_content, final_dump)\n",
    "final_dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
