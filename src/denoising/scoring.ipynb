{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed en\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scores/processed/denoised_scores_en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mga\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mde\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data, lang)\n\u001b[0;32m----> 5\u001b[0m     denoised_scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscores/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/denoised_scores_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m      6\u001b[0m     syn_scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/syn_scores_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/textbox/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scores/processed/denoised_scores_en'"
     ]
    }
   ],
   "source": [
    "diffs = {'synthetic': {}, 'processed': {}}\n",
    "for data in ['processed', 'synthetic']:\n",
    "    for lang in ['en', 'ga', 'de']:\n",
    "        print(data, lang)\n",
    "        denoised_scores = [float(i) for i in open(f'scores/{data}/denoised_scores_{lang}').readlines()]\n",
    "        syn_scores = [float(i) for i in open(f'scores/{data}/syn_scores_{lang}').readlines()]\n",
    "        if(data == 'processed'):\n",
    "            syn_scores = syn_scores[:-1]\n",
    "        diffs[data][lang] = np.array(denoised_scores) - np.array(syn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic en -1.0641810917480914 0.7702603745846928 6250\n",
      "synthetic ga -0.9350833649630985 0.6833910482771184 123\n",
      "synthetic de -1.0704608548300845 0.7203212966942848 2242\n",
      "processed en 1.657660816279002 0.621742158611325 34349\n",
      "processed ga 1.8709259184191953 0.7756332226565065 35421\n",
      "processed de 1.7828836510059631 0.664539469541866 17942\n"
     ]
    }
   ],
   "source": [
    "for data in diffs:\n",
    "    for lang in diffs[data]:\n",
    "        num_positive = len([i for i in diffs[data][lang] if i > 0])\n",
    "        print(data, lang, np.mean(diffs[data][lang]), np.std(diffs[data][lang]), num_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 en\n",
      "313685\n",
      "90602 90602\n",
      "2 en\n",
      "156842\n",
      "90602 90602\n",
      "3 en\n",
      "40602 40602\n",
      "1 ga\n",
      "9010\n",
      "44559 44559\n",
      "2 ga\n",
      "4505\n",
      "40054 40054\n",
      "3 ga\n",
      "35549 35549\n",
      "1 de\n",
      "238427\n",
      "70186 70186\n",
      "2 de\n",
      "119213\n",
      "70186 70186\n",
      "3 de\n",
      "20186 20186\n"
     ]
    }
   ],
   "source": [
    "for lang in ['en', 'ga', 'de']:\n",
    "    syn_src = open(f'/home2/aditya_hari/gsoc/data/synthetic/{lang}/train_src', 'r').readlines()[:-1]\n",
    "    syn_tgt = open(f'/home2/aditya_hari/gsoc/data/synthetic/{lang}/train_tgt', 'r').readlines()[:-1]\n",
    "\n",
    "    trusted_src = open(f'/home2/aditya_hari/gsoc/data/processed/{lang}/train_src', 'r').readlines()\n",
    "    trusted_tgt = open(f'/home2/aditya_hari/gsoc/data/processed/{lang}/train_tgt', 'r').readlines()\n",
    "    \n",
    "    for iter in range(1, 4):\n",
    "        print(iter, lang)\n",
    "        srcs = []\n",
    "        tgts = []\n",
    "\n",
    "        srcs.extend(trusted_src)\n",
    "        tgts.extend(trusted_tgt)\n",
    "        score_diff = diffs['synthetic'][lang]\n",
    "        triples = list(zip(syn_src, syn_tgt, score_diff))\n",
    "        triples = sorted(triples, key=lambda x: x[2], reverse=True)\n",
    "        for src, tgt, score in triples:\n",
    "            if(score > 0):\n",
    "                srcs.append(src)\n",
    "                tgts.append(tgt)\n",
    "\n",
    "        if(iter < 3):\n",
    "            non_positives = [i for i in triples if i[2] < 0][:len(triples)//(2*iter)]   \n",
    "            print(len(non_positives)) \n",
    "            # sample 50000 sentences \n",
    "            if(len(non_positives) > 50000):\n",
    "                sample_indices = np.random.choice(len(non_positives), 50000)\n",
    "            else:\n",
    "                sample_indices = np.random.choice(len(non_positives), len(non_positives))\n",
    "            for i in sample_indices:\n",
    "                srcs.append(non_positives[i][0])\n",
    "                tgts.append(non_positives[i][1])\n",
    "\n",
    "        print(len(srcs), len(tgts))\n",
    "        with open(f'/home2/aditya_hari/gsoc/rdf-to-text/src/denoising/data/iter{iter-1}/{lang}/train_src', 'w') as f:\n",
    "            f.write(''.join(srcs))\n",
    "        with open(f'/home2/aditya_hari/gsoc/rdf-to-text/src/denoising/data/iter{iter-1}/{lang}/train_tgt', 'w') as f:\n",
    "            f.write(''.join(tgts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('textbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fc63c8ae42b05f54f8c8e4c73411ce0404f059987aac7c448c556c45688d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
