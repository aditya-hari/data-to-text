{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "from transformers import MT5ForConditionalGeneration, EncoderDecoderModel, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorForSeq2Seq, Text2TextGenerationPipeline\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import random \n",
    "from sacrebleu import BLEU \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2TextDataset(Dataset):\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        #self.targets = targets\n",
    "        #self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_text = self.inputs[index]\n",
    "        #target_text = self.targets[index]\n",
    "        return input_text \n",
    "        # input_encoding = self.tokenizer.encode_plus(\n",
    "        #     input_text,\n",
    "        #     max_length=400,\n",
    "        #     padding=\"max_length\",\n",
    "        #     truncation=True,\n",
    "        #     return_tensors=\"pt\"\n",
    "        # )\n",
    "        # target_encoding = self.tokenizer.encode_plus(\n",
    "        #     target_text,\n",
    "        #     max_length=400,\n",
    "        #     padding=\"max_length\",\n",
    "        #     truncation=True,\n",
    "        #     return_tensors=\"pt\"\n",
    "        # )\n",
    "\n",
    "        # input_ids = input_encoding[\"input_ids\"].squeeze()\n",
    "        # attention_mask = input_encoding[\"attention_mask\"].squeeze()\n",
    "        # labels = target_encoding[\"input_ids\"].squeeze()\n",
    "\n",
    "        # return {\n",
    "        #     \"input_ids\": input_ids,\n",
    "        #     \"attention_mask\": attention_mask,\n",
    "        #     \"labels\": labels\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "    \"cy\": \"Welsh\",\n",
    "    \"br\": \"Breton\",\n",
    "    \"ga\": \"Irish\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"de\": \"German\",\n",
    "    \"en\": \"English\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/aditya_hari/miniconda3/envs/textbox/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['/scratch/aditya_hari/gsoc/mt5_pro/', '/scratch/aditya_hari/gsoc/mt5_denoised', '/scratch/aditya_hari/gsoc/mt5-iter-final/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_data = {}\n",
    "for lang in ['en', 'de', 'ga']:\n",
    "    eval_srcs = [] \n",
    "    eval_tgts = []\n",
    "    eval_src = open(f'/home2/aditya_hari/gsoc/data/processed/{lang}/eval_src', 'r').readlines()\n",
    "    eval_tgt = open(f'/home2/aditya_hari/gsoc/data/processed/{lang}/eval_tgt', 'r').readlines()\n",
    "    eval_srcs.extend([re.sub(r\"[ ]{2,}\", \" \" , f\"generate {lang_codes[lang]} : {line}\").strip() for line in eval_src])\n",
    "    eval_tgts.extend([line.strip() for line in eval_tgt])\n",
    "    lang_data[lang] = [eval_srcs, eval_tgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_pro/ en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 192/869 [00:39<02:21,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_pro/ de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [00:31<00:00, 51.14it/s]\n",
      "100%|█████████▉| 865/869 [00:17<00:00, 57.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_pro/ ga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:17<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_denoised en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1665/1665 [00:40<00:00, 41.22it/s]\n",
      " 99%|█████████▉| 1601/1618 [00:31<00:00, 52.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_denoised de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [00:31<00:00, 51.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_denoised ga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:17<00:00, 50.35it/s]\n",
      "100%|██████████| 1665/1665 [00:46<00:00, 58.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1665/1665 [00:49<00:00, 33.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [00:31<00:00, 51.03it/s]\n",
      "100%|█████████▉| 865/869 [00:17<00:00, 57.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ ga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:17<00:00, 50.44it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = {}\n",
    "for model_name in model_names:\n",
    "    pipe = Text2TextGenerationPipeline(model=MT5ForConditionalGeneration.from_pretrained(model_name), tokenizer=tokenizer, batch_size=32, device=0, num_beams=5, early_stopping=True)\n",
    "    for lang in ['en', 'de', 'ga']:\n",
    "        print(model_name, lang)\n",
    "        pb = tqdm.tqdm(total=len(lang_data[lang][0]))\n",
    "        if(model_name not in outputs):\n",
    "            outputs[model_name] = {}\n",
    "        outs = [] \n",
    "        for out in pipe(Text2TextDataset(lang_data[lang][0])):\n",
    "            pb.update(1)\n",
    "            gen_texts = [i['generated_text'] for i in out]\n",
    "            outs.extend(gen_texts)\n",
    "        outputs[model_name][lang] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Der Flughafen Aarhus hat eine Fahrbahnlänge von 2702,0.',\n",
       " 'Der Flughafen Aarhus hat eine Fahrbahnlänge von 2702,0.',\n",
       " 'Der Flughafen Aarhus hat eine Fahrbahnlänge von 2702.0.')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[list(outputs.keys())[0]]['de'][1], outputs[list(outputs.keys())[1]]['de'][1], outputs[list(outputs.keys())[2]]['de'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aditya_hari/gsoc/mt5_pro/ en 20.752479348448915\n",
      "/scratch/aditya_hari/gsoc/mt5_pro/ de 17.178769427498807\n",
      "/scratch/aditya_hari/gsoc/mt5_pro/ ga 5.043527832978668\n",
      "/scratch/aditya_hari/gsoc/mt5_denoised en 20.682504286538787\n",
      "/scratch/aditya_hari/gsoc/mt5_denoised de 18.017464181172844\n",
      "/scratch/aditya_hari/gsoc/mt5_denoised ga 5.012456607532915\n",
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ en 20.849497028402883\n",
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ de 17.83210463595681\n",
      "/scratch/aditya_hari/gsoc/mt5-iter-final/ ga 4.838849603775116\n"
     ]
    }
   ],
   "source": [
    "for model_name in outputs:\n",
    "    for lang in outputs[model_name]:\n",
    "        ref = lang_data[lang][1]\n",
    "        hyp = outputs[model_name][lang]\n",
    "        with(open(f'/home2/aditya_hari/gsoc/rdf-to-text/src/denoising/outputs/{lang}/{model_name.split(\"/\")[-2]}', 'w')) as f:\n",
    "            f.write('\\n'.join(hyp))\n",
    "        print(model_name, lang, bleu.corpus_score(hyp, [ref]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-distilroberta-v1\")\n",
    "tokenizer_other = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50266, 768, padding_idx=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EncoderDecoderModel.from_pretrained(\"/scratch/aditya_hari/gsoc/s2s_sbert_van\")\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<TSP>']})\n",
    "model.encoder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbert_s2s en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1665/1665 [08:53<00:00,  3.12it/s]\n",
      "/home2/aditya_hari/miniconda3/envs/textbox/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "100%|█████████▉| 1617/1618 [00:53<00:00, 31.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbert_s2s de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [00:53<00:00, 30.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbert_s2s ga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:29<00:00, 29.49it/s]\n",
      "100%|██████████| 1665/1665 [00:55<00:00, 31.17it/s]"
     ]
    }
   ],
   "source": [
    "pipe = Text2TextGenerationPipeline(model=model, tokenizer=tokenizer, batch_size=16, device=0, num_beams=5, early_stopping=True)\n",
    "model_name = 'sbert_van'\n",
    "for lang in ['en', 'de', 'ga']:\n",
    "    print(model_name, lang)\n",
    "    pb = tqdm.tqdm(total=len(lang_data[lang][0]))\n",
    "    if(model_name not in outputs):\n",
    "        outputs[model_name] = {}\n",
    "    outs = [] \n",
    "    for out in pipe(Text2TextDataset(lang_data[lang][0])):\n",
    "        pb.update(1)\n",
    "        gen_texts = [i['generated_text'] for i in out]\n",
    "        outs.extend(gen_texts)\n",
    "    outputs[model_name][lang] = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('textbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fc63c8ae42b05f54f8c8e4c73411ce0404f059987aac7c448c556c45688d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
